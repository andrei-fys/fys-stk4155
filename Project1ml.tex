\documentclass[10pt]{article}
\usepackage{mathtools}
\usepackage{amsmath}
\usepackage{tabularx}
\usepackage{graphicx}
\usepackage{flexisym}
\usepackage{listings}
\usepackage{xcolor}
\usepackage{hyperref}
\usepackage{amsthm}
\usepackage{subcaption}
\newtheorem*{theorem}{Theorem}
\newtheorem{defn}{Definition}
\begin{document}
\setlength\parindent{1pt}
\title{Data Analysis and Machine Learning \\
Project1.\\ Regression analysis and re-sampling methods}
\author{Andrei Kukharenka, Anton Fofanov and Anna Gribkovskaya \\  
FYS-STK 4155 
}

\maketitle
\begin{abstract}
In this project we have performed the Ordinary Least Squares (OSL), Ridge and Lasso regression. The solvers for OSL and Ridge have been developed from scratch and the Lasso regression have been implemented using a Sci-Kit learn library. The estimators were used on the test Franke function (REF) and on the real data - terrain data for Norway.The k-fold cross validation for all the methods have been also implemented and the bias-variance was studied for all the models.\\
ADD SOME RESULTS HERE!!!!!
\end{abstract}
\clearpage 


\section*{Introduction}
Regression analysis is a widely used tool in data science. It incorporates many different techniques and models for estimating relations between variables. In this project we aim to study most widely used estimators - OSL, Ridge and Lasso.
OSL regression is one of the most popular models here. It has been implemented in many software packages is various programming languages and is used by many data scientist everyday for performing analysis. In this project we aim to implement it from scratch in order to have a better understanding of its machinery. Rigde regression is also implemented from scratch here. \\
A regression analysis aims to find the relations between various variables not only to explain or extract a functional dependency, but also to be able to predict outcomes for some unknown values of this variables. Here we need to be very careful with our model, because even if we were able to implement it with the smallest possible error and even hit all the variables provided for estimation of the relations, we can't be sure it will provide same good results when applied to the new set of data. The problem here is a possibility of over-fitting.In order to prevent this we use so-called re-sampling and cross-validation. In this project a k-fold cross validation have beed applied for all three methods. ADD SOME RESULTS HERE!!!\\
Structure of the report:\\
In section $\ref{Theory}$ we provide a brief theoretical review of the implemented models and re-sampling techniques.\\

\section{General description of the linear regression methods} \label{Theory}
Regression analysis is a powerful tool to analyze the data. Let's start with some definitions needed to understand how it works.
\begin{defn}
Variables $\hat{x} = [x_0,x_1, x_2,\dots, x_{n-1}]^T,$ are called independent  or explanatory variable. Here $n$ is number of samples measured.
\end{defn}

\begin{defn}
	Variables  $\hat{y} = [y_0,y_1, y_2,\dots, y_{n-1}]^T,$ are called dependent or response variable. Here $n$ is number of samples measured.
\end{defn}
The aim of the regression is to estimate the relationship between $\hat{x}$ and $\hat{y}$ variables in order to make predictions and find functional dependences. \\
Let's assume we measure a set of parameters for each sample. Number of parameters is denoted by $p$. In this case instead for vector we would get a matrix $\textbf{X}$ and $\textbf{Y}$. Matrix $\textbf{X}$ is called \textbf{design matrix} and matrix $\textbf{Y}$ is \textbf{response matrix}. Goal of regression analysis is to determine the functional dependence between $\textbf{X}$ and $\textbf{Y}$ or one may say explain one in terms of the other. Here we have no knowledge on the function is available in advance. However one may assume the function to be linear with respect to some unknown parameters $\beta = (\beta_1, \ldots, \beta_p)^{\top}$.Such assumption leads to so called \textbf{linear regression} and set of $\beta$  are \textbf{regression parameters}. There are many types of linear regressions and in the sections below we are going to describe some of them.
\subsection{Ordinary Least Squared}

\subsection{Ridge}

\subsection{Lasso}

\subsection{Re-sampling methods}
As we have already mention the main goal of regression analysis is to find the relations between the dependent and independent variables by estimating set of parameters. Once we have sampled the date and run the regression analysis we have obtained this parameters. However we only can do it once for a single data sample and can't predict how the model we have made will explain new data. The process of collecting data might also be expensive both in computational time and in real life currency, so one might need a recipe to avoid collecting more data and re-use the existing. Another problem here is so-called over-fitting. Regression analysis is base on the idea of prediction for the value based on some already known sets of variables and 


\section{Results and discussion} \label{Results}

\section{Conclusion}\label{Conclusion}

\end{document}
